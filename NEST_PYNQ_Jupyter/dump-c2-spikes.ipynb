{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSAConnector: libneurosim support not available in NEST.\n",
      "Falling back on PyNN's default CSAConnector.\n",
      "Please re-compile NEST using --with-libneurosim=PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pyNN/nest/__init__.py:53: UserWarning: Unable to install NEST extensions. Certain models may not be available.\n",
      "  warnings.warn(\"Unable to install NEST extensions. Certain models may not be available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create C1 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 creation took 68.15743900000001 s\n",
      "Creating S2 layers and reading the epoch weights\n",
      "S2 Shape 11 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2 Shape 8 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2 Shape 6 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2 Shape 4 5\n",
      "Setting labels took 2.599999999119973e-05\n",
      "Create S2 self inhibitory connections\n",
      "Create S2 cross-scale inhibitory connections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating C2 layers\n",
      "C2 creation took 0.5590890000000002 s\n",
      "Setting S2 weights to epoch 20\n",
      "Setting C1 spike trains to the training dataset\n",
      ">>>>>>>>> Extracting spike trains for learning <<<<<<<<<\n",
      "========= Start simulation =========\n",
      "Simulating for 20 images\n",
      "========= Stop  simulation =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting C1 spike trains to the validation dataset\n",
      ">>>>>>>>> Extracting spike trains for validation <<<<<<<<<\n",
      "========= Start simulation =========\n",
      "Simulating for 20 images\n",
      "========= Stop  simulation =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n",
      "NEST does not allow setting an initial value for isyn_exc\n",
      "NEST does not allow setting an initial value for isyn_inh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping C2 training spikes to file C2_spikes/train_20imgs_50ms_199px_scales_1.0_0.71_0.5_0.35_fs3_3prots.bin\n",
      "Dumping C2 validation spikes to file C2_spikes/validation_20imgs_50ms_199px_scales_1.0_0.71_0.5_0.35_fs3_3prots.bin\n"
     ]
    }
   ],
   "source": [
    "#!/bin/ipython\n",
    "\n",
    "# ---LICENSE-BEGIN - DO NOT CHANGE OR MOVE THIS HEADER\n",
    "# This file is part of the Neurorobotics Platform software\n",
    "# Copyright (C) 2014,2015,2016,2017 Human Brain Project\n",
    "#\n",
    "# This program is free software; you can redistribute it and/or\n",
    "# modify it under the terms of the GNU General Public License\n",
    "# as published by the Free Software Foundation; either version 2\n",
    "# of the License, or (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program; if not, write to the Free Software\n",
    "# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n",
    "# ---LICENSE-END\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/xilinx/nest/lib/python3.6/site-packages')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyNN.nest as sim\n",
    "import pathlib as plb\n",
    "import time\n",
    "import pickle\n",
    "import argparse as ap\n",
    "import re\n",
    "\n",
    "import network as nw\n",
    "\n",
    "# parser = ap.ArgumentParser('./dump-c2-spikes.py --')\n",
    "# parser.add_argument('--training-c1-dumpfile', type=str, required=True,\n",
    "#                     help='The output file to contain the C1 spiketrains for\\\n",
    "#                          training')\n",
    "# parser.add_argument('--validation-c1-dumpfile', type=str, required=True,\n",
    "#                     help='The output file to contain the C1 spiketrains for\\\n",
    "#                          validation')\n",
    "# parser.add_argument('--threads', default=1, type=int)\n",
    "# parser.add_argument('--weights-from', type=str, required=True,\n",
    "#                     help='Dumpfile of the S2 weight array')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "training_c1_dumpfile='/home/xilinx/jupyter_notebooks/snn_object_recognition/C1_spikes/train_20imgs_50ms_199px_scales_1.0_0.71_0.5_0.35.bin'\n",
    "validation_c1_dumpfile='/home/xilinx/jupyter_notebooks/snn_object_recognition/C1_spikes/validation_20imgs_50ms_199px_scales_1.0_0.71_0.5_0.35.bin'\n",
    "weights_from='/home/xilinx/jupyter_notebooks/snn_object_recognition/S2_weights/train_20imgs_50ms_199px_scales_1.0_0.71_0.5_0.35_fs3_3prots.bin'\n",
    "threads=1\n",
    "\n",
    "\n",
    "sim.setup(threads=threads, min_delay=.1)\n",
    "\n",
    "layer_collection = {}\n",
    "\n",
    "# Extracting meta-information about the simulation from the filename\n",
    "training_dumpfile_name = plb.Path(training_c1_dumpfile).stem\n",
    "validation_dumpfile_name = plb.Path(validation_c1_dumpfile).stem\n",
    "training_image_count = int(re.search('\\d*imgs',\n",
    "                                     training_dumpfile_name).group()[:-4])\n",
    "validation_image_count = int(re.search('\\d*imgs',\n",
    "                                       validation_dumpfile_name).group()[:-4])\n",
    "training_sim_time = float(re.search('\\d*ms',\n",
    "                                        training_dumpfile_name).group()[:-2])\n",
    "validation_sim_time = float(re.search('\\d*ms',\n",
    "                                        validation_dumpfile_name).group()[:-2])\n",
    "blanktime = 0\n",
    "occurrence = re.search('\\d+\\.\\d+blank', training_dumpfile_name)\n",
    "if occurrence is not None:\n",
    "    blanktime = float(occurrence.group()[:-5])\n",
    "\n",
    "print('Create C1 layers')\n",
    "t1 = time.clock()\n",
    "training_ddict = pickle.load(open(training_c1_dumpfile, 'rb'))\n",
    "validation_ddict = pickle.load(open(validation_c1_dumpfile, 'rb'))\n",
    "layer_collection['C1'] = {}\n",
    "for size, layers_as_dicts in training_ddict.items():\n",
    "    layer_list = []\n",
    "    for layer_as_dict in layers_as_dicts:\n",
    "        n, m = layer_as_dict['shape']\n",
    "        new_layer = nw.Layer(sim.Population(n * m,\n",
    "                        sim.SpikeSourceArray(),\n",
    "                        label=layer_as_dict['label']), (n, m))\n",
    "        layer_list.append(new_layer)\n",
    "    layer_collection['C1'][size] = layer_list\n",
    "print('C1 creation took {} s'.format(time.clock() - t1))\n",
    "\n",
    "print('Creating S2 layers and reading the epoch weights')\n",
    "epoch_weights_list = pickle.load(open(weights_from, 'rb'))\n",
    "epoch = epoch_weights_list[-1][0]\n",
    "weights_dict_list = epoch_weights_list[-1][1]\n",
    "f_s = int(np.sqrt(list(weights_dict_list[0].values())[0].shape[0]))\n",
    "s2_prototype_cells = len(weights_dict_list)\n",
    "layer_collection['S2'] = nw.create_S2_layers(layer_collection['C1'], f_s,\n",
    "                                             s2_prototype_cells, refrac_s2=.1,\n",
    "                                             stdp=False, inhibition=True)\n",
    "\n",
    "print('Creating C2 layers')\n",
    "t1 = time.clock()\n",
    "layer_collection['C2'] = nw.create_C2_layers(layer_collection['S2'],\n",
    "                                             s2_prototype_cells)\n",
    "print('C2 creation took {} s'.format(time.clock() - t1))\n",
    "\n",
    "for pop in layer_collection['C2']:\n",
    "    pop.record('spikes')\n",
    "\n",
    "def set_c1_spiketrains(ddict):\n",
    "    for size, layers_as_dicts in ddict.items():\n",
    "        for layer_as_dict in layers_as_dicts:\n",
    "            spiketrains = layer_as_dict['segment'].spiketrains\n",
    "            dimensionless_sts = [[s for s in st] for st in spiketrains]\n",
    "            the_layer_iter = filter(lambda layer: layer.population.label\\\n",
    "                            == layer_as_dict['label'], layer_collection['C1'][size])\n",
    "            the_layer_iter.__next__().population.set(spike_times=dimensionless_sts)\n",
    "\n",
    "def extract_spiketrains(image_count, sim_time):\n",
    "    print('========= Start simulation =========')\n",
    "    print('Simulating for', image_count, 'images')\n",
    "    sim.run((sim_time + blanktime) * image_count)\n",
    "    print('========= Stop  simulation =========')\n",
    "    return [layer_collection['C2'][prot].get_data(clear=True).segments[0]\\\n",
    "                .spiketrains[0] for prot in range(s2_prototype_cells)]\n",
    "\n",
    "c2_training_spikes = []\n",
    "c2_validation_spikes = []\n",
    "\n",
    "for epoch, weights_dict_list in epoch_weights_list:\n",
    "    # Set the S2 weights to those from the file\n",
    "    print('Setting S2 weights to epoch', epoch)\n",
    "    for prototype in range(s2_prototype_cells):\n",
    "        nw.set_s2_weights(layer_collection['S2'], prototype,\n",
    "                          weights_dict_list=weights_dict_list)\n",
    "\n",
    "    print('Setting C1 spike trains to the training dataset')\n",
    "    set_c1_spiketrains(training_ddict)\n",
    "    # Let the simulation run to \"fill\" the layer pipeline with spikes\n",
    "    sim.run(40)\n",
    "    print('>>>>>>>>> Extracting spike trains for learning <<<<<<<<<')\n",
    "    c2_training_spikes.append((epoch,\n",
    "                  extract_spiketrains(training_image_count, training_sim_time)))\n",
    "    sim.reset()\n",
    "\n",
    "    print('Setting C1 spike trains to the validation dataset')\n",
    "    set_c1_spiketrains(validation_ddict)\n",
    "    # Let the simulation run to \"fill\" the layer pipeline with spikes\n",
    "    sim.run(40)\n",
    "    print('>>>>>>>>> Extracting spike trains for validation <<<<<<<<<')\n",
    "    c2_validation_spikes.append((epoch,\n",
    "              extract_spiketrains(validation_image_count, validation_sim_time)))\n",
    "    sim.reset()\n",
    "\n",
    "c2_training_dumpfile_name = 'C2_spikes/{}_fs{}_{}prots.bin'\\\n",
    "                      .format(training_dumpfile_name, f_s, s2_prototype_cells)\n",
    "c2_validation_dumpfile_name = 'C2_spikes/{}_fs{}_{}prots.bin'\\\n",
    "                      .format(validation_dumpfile_name, f_s, s2_prototype_cells)\n",
    "c2_training_dumpfile = open(c2_training_dumpfile_name, 'wb')\n",
    "c2_validation_dumpfile = open(c2_validation_dumpfile_name, 'wb')\n",
    "print('Dumping C2 training spikes to file', c2_training_dumpfile_name)\n",
    "print('Dumping C2 validation spikes to file', c2_validation_dumpfile_name)\n",
    "pickle.dump(c2_training_spikes, c2_training_dumpfile, protocol=4)\n",
    "pickle.dump(c2_validation_spikes, c2_validation_dumpfile, protocol=4)\n",
    "\n",
    "sim.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
